from bs4 import BeautifulSoup
import requests
from thefuzz import process


LINK = "https://ic2s2-2023.org/program"
r = requests.get(LINK)
soup = BeautifulSoup(r.content) 


scrape = soup.find_all("i")


names = []
for i in scrape:
    for name in i.strings:
        names.append(name)


scrape2 = soup.find_all("a")


for i in scrape2:
    str = i.get_text(strip=True)
    if 'Keynote -' in str:
        names.append(str.replace("Keynote - ", "").strip())


cleaned_names = []
for name in names:
    name = name.removeprefix("Chair: ") 
    split_names = [n.strip() for n in name.split(",") if n.strip()] 
    cleaned_names.extend(split_names)

print(len(cleaned_names))



unique_names = []
seen = set()

for name in cleaned_names:
    normalized_name = name.lower()
    
    match = process.extractOne(normalized_name, seen, score_cutoff=85) if seen else None
    
    if match is None:  
        unique_names.append(name)
        seen.add(normalized_name)


print(len(unique_names))


for name in unique_names:
    if len(name.split()) < 2:
        unique_names.remove(name)


with open("web_scraped_names.txt", "w", encoding="utf-8") as file:
    for name in unique_names:
        file.write(name + "\n")



